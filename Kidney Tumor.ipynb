{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kdWpeoTvf_9h"
   },
   "source": [
    "## This is the major start of our code, where we are getting data from github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "colab_type": "code",
    "id": "9sTvUuC0b54c",
    "outputId": "87e96a91-c745-450d-9dff-23eb2251cb8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected operating system as Ubuntu/bionic.\n",
      "Checking for curl...\n",
      "Detected curl...\n",
      "Checking for gpg...\n",
      "Detected gpg...\n",
      "Running apt-get update... done.\n",
      "Installing apt-transport-https... done.\n",
      "Installing /etc/apt/sources.list.d/github_git-lfs.list...done.\n",
      "Importing packagecloud gpg key... done.\n",
      "Running apt-get update... done.\n",
      "\n",
      "The repository is setup! You can now install packages.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'sudo apt autoremove' to remove it.\n",
      "The following NEW packages will be installed:\n",
      "  git-lfs\n",
      "0 upgraded, 1 newly installed, 0 to remove and 53 not upgraded.\n",
      "Need to get 6,877 kB of archives.\n",
      "After this operation, 16.4 MB of additional disk space will be used.\n",
      "Get:1 https://packagecloud.io/github/git-lfs/ubuntu bionic/main amd64 git-lfs amd64 2.11.0 [6,877 kB]\n",
      "Fetched 6,877 kB in 1s (13.4 MB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package git-lfs.\n",
      "(Reading database ... 144332 files and directories currently installed.)\n",
      "Preparing to unpack .../git-lfs_2.11.0_amd64.deb ...\n",
      "Unpacking git-lfs (2.11.0) ...\n",
      "Setting up git-lfs (2.11.0) ...\n",
      "Git LFS initialized.\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Git LFS initialized.\n",
      "Cloning into 'kits19'...\n",
      "remote: Enumerating objects: 954, done.\u001b[K\n",
      "remote: Counting objects: 100% (954/954), done.\u001b[K\n",
      "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
      "remote: Total 991 (delta 433), reused 927 (delta 408), pack-reused 37\u001b[K\n",
      "Receiving objects: 100% (991/991), 29.70 MiB | 36.38 MiB/s, done.\n",
      "Resolving deltas: 100% (451/451), done.\n"
     ]
    }
   ],
   "source": [
    "! curl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\n",
    "! sudo apt-get install git-lfs\n",
    "! git lfs install\n",
    "! git clone https://github.com/neheller/kits19.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Oz_vlNAhcBJy",
    "outputId": "6edc58b4-bcb3-4119-dc35-6d6967a26029"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/kits19\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 1)) (1.18.5)\n",
      "Requirement already satisfied: nibabel in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 2)) (3.0.2)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 4)) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r /content/kits19/requirements.txt (line 5)) (4.41.1)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio->-r /content/kits19/requirements.txt (line 3)) (7.0.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r /content/kits19/requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r /content/kits19/requirements.txt (line 4)) (2020.4.5.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r /content/kits19/requirements.txt (line 4)) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r /content/kits19/requirements.txt (line 4)) (1.24.3)\n",
      "300 cases to download...\n",
      "Download 1/300: \n",
      "case_00000: 100% 225959/225960 [00:04<00:00, 55735.16KB/s]\n",
      "Download 2/300: \n",
      "case_00001: 100% 276387/276388 [00:04<00:00, 56264.35KB/s]\n",
      "Download 3/300: \n",
      "case_00002: 100% 101967/101968 [00:01<00:00, 52339.29KB/s]\n",
      "Download 4/300: \n",
      "case_00003: 100% 118681/118682 [00:02<00:00, 51294.15KB/s]\n",
      "Download 5/300: \n",
      "case_00004: 100% 25269/25270 [00:00<00:00, 36380.65KB/s]\n",
      "Download 6/300: \n",
      "case_00005: 100% 313477/313478 [00:05<00:00, 57029.71KB/s]\n",
      "Download 7/300: \n",
      "case_00006: 100% 78010/78011 [00:01<00:00, 47687.39KB/s]\n",
      "Download 8/300: \n",
      "case_00007: 100% 25826/25827 [00:00<00:00, 37506.94KB/s]\n",
      "Download 9/300: \n",
      "case_00008: 100% 107068/107069 [00:02<00:00, 52981.67KB/s]\n",
      "Download 10/300: \n",
      "case_00009: 100% 34134/34135 [00:00<00:00, 35732.92KB/s]\n",
      "Download 11/300: \n",
      "case_00010: 100% 23541/23542 [00:00<00:00, 35046.14KB/s]\n",
      "Download 12/300: \n",
      "case_00011: 100% 41268/41269 [00:00<00:00, 43260.05KB/s]\n",
      "Download 13/300: \n",
      "case_00012: 100% 43185/43186 [00:01<00:00, 40933.65KB/s]\n",
      "Download 14/300: \n",
      "case_00013: 100% 44485/44486 [00:01<00:00, 43498.31KB/s]\n",
      "Download 15/300: \n",
      "case_00014: 100% 192486/192487 [00:03<00:00, 55095.89KB/s]\n",
      "Download 16/300: \n",
      "case_00015: 100% 23795/23796 [00:00<00:00, 39640.68KB/s]\n",
      "Download 17/300: \n",
      "case_00016: 100% 86929/86930 [00:01<00:00, 47479.74KB/s]\n",
      "Download 18/300: \n",
      "case_00017: 100% 49940/49941 [00:01<00:00, 43803.98KB/s]\n",
      "Download 19/300: \n",
      "case_00018: 100% 49984/49985 [00:01<00:00, 41522.40KB/s]\n",
      "Download 20/300: \n",
      "case_00019: 100% 51644/51645 [00:01<00:00, 45541.08KB/s]\n",
      "Download 21/300: \n",
      "case_00020: 100% 43148/43149 [00:01<00:00, 42261.04KB/s]\n",
      "Download 22/300: \n",
      "case_00021: 100% 17267/17268 [00:00<00:00, 32395.21KB/s]\n",
      "Download 23/300: \n",
      "case_00022: 100% 235518/235519 [00:04<00:00, 47290.53KB/s]\n",
      "Download 24/300: \n",
      "case_00023: 100% 45338/45339 [00:01<00:00, 43224.82KB/s]\n",
      "Download 25/300: \n",
      "case_00024: 100% 43319/43320 [00:01<00:00, 43108.08KB/s]\n",
      "Download 26/300: \n",
      "case_00025: 100% 42608/42609 [00:00<00:00, 43107.63KB/s]\n",
      "Download 27/300: \n",
      "case_00026: 100% 128953/128954 [00:02<00:00, 50402.76KB/s]\n",
      "Download 28/300: \n",
      "case_00027: 100% 300960/300961 [00:05<00:00, 56348.75KB/s]\n",
      "Download 29/300: \n",
      "case_00028: 100% 45001/45002 [00:00<00:00, 45301.10KB/s]\n",
      "Download 30/300: \n",
      "case_00029: 100% 62472/62473 [00:01<00:00, 45694.39KB/s]\n",
      "Download 31/300: \n",
      "case_00030: 100% 18676/18677 [00:00<00:00, 34051.47KB/s]\n",
      "Download 32/300: \n",
      "case_00031: 100% 50504/50505 [00:01<00:00, 45190.95KB/s]\n",
      "Download 33/300: \n",
      "case_00032: 100% 75286/75287 [00:01<00:00, 47439.66KB/s]\n",
      "Download 34/300: \n",
      "case_00033: 100% 191873/191874 [00:03<00:00, 54905.35KB/s]\n",
      "Download 35/300: \n",
      "case_00034: 100% 52752/52753 [00:01<00:00, 44735.49KB/s]\n",
      "Download 36/300: \n",
      "case_00035: 100% 39633/39634 [00:01<00:00, 39228.14KB/s]\n",
      "Download 37/300: \n",
      "case_00036: 100% 78614/78615 [00:01<00:00, 49899.30KB/s]\n",
      "Download 38/300: \n",
      "case_00037: 100% 40424/40425 [00:00<00:00, 42880.26KB/s]\n",
      "Download 39/300: \n",
      "case_00038: 100% 15415/15416 [00:00<00:00, 23219.42KB/s]\n",
      "Download 40/300: \n",
      "case_00039: 100% 44953/44954 [00:01<00:00, 43910.97KB/s]\n",
      "Download 41/300: \n",
      "case_00040: 100% 81954/81955 [00:01<00:00, 48120.03KB/s]\n",
      "Download 42/300: \n",
      "case_00041: 100% 25224/25225 [00:00<00:00, 36919.54KB/s]\n",
      "Download 43/300: \n",
      "case_00042: 100% 136618/136619 [00:02<00:00, 52211.85KB/s]\n",
      "Download 44/300: \n",
      "case_00043: 100% 70644/70645 [00:01<00:00, 48278.84KB/s]\n",
      "Download 45/300: \n",
      "case_00044: 100% 38419/38420 [00:00<00:00, 40660.86KB/s]\n",
      "Download 46/300: \n",
      "case_00045: 100% 25584/25585 [00:00<00:00, 38722.76KB/s]\n",
      "Download 47/300: \n",
      "case_00046: 100% 59261/59262 [00:01<00:00, 48435.05KB/s]\n",
      "Download 48/300: \n",
      "case_00047: 100% 63514/63515 [00:01<00:00, 48702.12KB/s]\n",
      "Download 49/300: \n",
      "case_00048: 100% 30867/30868 [00:00<00:00, 36348.81KB/s]\n",
      "Download 50/300: \n",
      "case_00049: 100% 289194/289195 [00:05<00:00, 55240.80KB/s]\n",
      "Download 51/300: \n",
      "case_00050: 100% 40193/40194 [00:00<00:00, 41372.16KB/s]\n",
      "Download 52/300: \n",
      "case_00051: 100% 25645/25646 [00:01<00:00, 19783.50KB/s]\n",
      "Download 53/300: \n",
      "case_00052: 100% 256991/256992 [00:04<00:00, 56385.05KB/s]\n",
      "Download 54/300: \n",
      "case_00053: 100% 251298/251299 [00:04<00:00, 56571.95KB/s]\n",
      "Download 55/300: \n",
      "case_00054: 100% 41865/41866 [00:01<00:00, 40819.08KB/s]\n",
      "Download 56/300: \n",
      "case_00055: 100% 43342/43343 [00:00<00:00, 43531.55KB/s]\n",
      "Download 57/300: \n",
      "case_00056: 100% 45668/45669 [00:01<00:00, 45070.09KB/s]\n",
      "Download 58/300: \n",
      "case_00057: 100% 37609/37610 [00:00<00:00, 43169.68KB/s]\n",
      "Download 59/300: \n",
      "case_00058: 100% 43100/43101 [00:01<00:00, 39748.66KB/s]\n",
      "Download 60/300: \n",
      "case_00059: 100% 324407/324408 [00:05<00:00, 55789.32KB/s]\n",
      "Download 61/300: \n",
      "case_00060: 100% 62615/62616 [00:01<00:00, 47113.48KB/s]\n",
      "Download 62/300: \n",
      "case_00061: 100% 11577/11578 [00:00<00:00, 26499.22KB/s]\n",
      "Download 63/300: \n",
      "case_00062: 100% 32540/32541 [00:00<00:00, 39546.98KB/s]\n",
      "Download 64/300: \n",
      "case_00063: 100% 231715/231716 [00:04<00:00, 54211.93KB/s]\n",
      "Download 65/300: \n",
      "case_00064: 100% 21721/21722 [00:00<00:00, 34768.35KB/s]\n",
      "Download 66/300: \n",
      "case_00065: 100% 48274/48275 [00:01<00:00, 45933.90KB/s]\n",
      "Download 67/300: \n",
      "case_00066: 100% 186603/186604 [00:03<00:00, 54503.61KB/s]\n",
      "Download 68/300: \n",
      "case_00067: 100% 134477/134478 [00:02<00:00, 53333.97KB/s]\n",
      "Download 69/300: \n",
      "case_00068: 100% 300829/300830 [00:05<00:00, 54277.34KB/s]\n",
      "Download 70/300: \n",
      "case_00069: 100% 46183/46184 [00:01<00:00, 39115.44KB/s]\n",
      "Download 71/300: \n",
      "case_00070: 100% 29478/29479 [00:00<00:00, 38671.31KB/s]\n",
      "Download 72/300: \n",
      "case_00071: 100% 268825/268826 [00:04<00:00, 55523.81KB/s]\n",
      "Download 73/300: \n",
      "case_00072: 100% 79384/79385 [00:01<00:00, 45343.16KB/s]\n",
      "Download 74/300: \n",
      "case_00073: 100% 66227/66228 [00:01<00:00, 45304.65KB/s]\n",
      "Download 75/300: \n",
      "case_00074: 100% 39078/39079 [00:00<00:00, 41485.38KB/s]\n",
      "Download 76/300: \n",
      "case_00075: 100% 44705/44706 [00:01<00:00, 44355.76KB/s]\n",
      "Download 77/300: \n",
      "case_00076: 100% 32585/32586 [00:00<00:00, 40797.16KB/s]\n",
      "Download 78/300: \n",
      "case_00077: 100% 42628/42629 [00:01<00:00, 29985.61KB/s]\n",
      "Download 79/300: \n",
      "case_00078: 100% 132219/132220 [00:02<00:00, 52621.47KB/s]\n",
      "Download 80/300: \n",
      "case_00079: 100% 60760/60761 [00:01<00:00, 49666.53KB/s]\n",
      "Download 81/300: \n",
      "case_00080: 100% 43158/43159 [00:00<00:00, 45554.53KB/s]\n",
      "Download 82/300: \n",
      "case_00081: 100% 60350/60351 [00:01<00:00, 44573.87KB/s]\n",
      "Download 83/300: \n",
      "case_00082: 100% 57346/57347 [00:01<00:00, 46406.86KB/s]\n",
      "Download 84/300: \n",
      "case_00083: 100% 38295/38296 [00:00<00:00, 39980.94KB/s]\n",
      "Download 85/300: \n",
      "case_00084: 100% 112681/112682 [00:02<00:00, 50897.19KB/s]\n",
      "Download 86/300: \n",
      "case_00085: 100% 36294/36295 [00:00<00:00, 41359.23KB/s]\n",
      "Download 87/300: \n",
      "case_00086: 100% 81962/81963 [00:01<00:00, 48204.86KB/s]\n",
      "Download 88/300: \n",
      "case_00087: 100% 25303/25304 [00:00<00:00, 36508.52KB/s]\n",
      "Download 89/300: \n",
      "case_00088: 100% 47969/47970 [00:01<00:00, 41338.61KB/s]\n",
      "Download 90/300: \n",
      "case_00089: 100% 24690/24691 [00:00<00:00, 32318.97KB/s]\n",
      "Download 91/300: \n",
      "case_00090: 100% 35861/35862 [00:00<00:00, 41001.08KB/s]\n",
      "Download 92/300: \n",
      "case_00091: 100% 320735/320736 [00:05<00:00, 54347.56KB/s]\n",
      "Download 93/300: \n",
      "case_00092: 100% 51076/51077 [00:01<00:00, 43096.51KB/s]\n",
      "Download 94/300: \n",
      "case_00093: 100% 324309/324310 [00:05<00:00, 55381.95KB/s]\n",
      "Download 95/300: \n",
      "case_00094: 100% 17428/17429 [00:00<00:00, 31578.07KB/s]\n",
      "Download 96/300: \n",
      "case_00095: 100% 127649/127650 [00:02<00:00, 52184.95KB/s]\n",
      "Download 97/300: \n",
      "case_00096: 100% 303181/303182 [00:05<00:00, 56570.84KB/s]\n",
      "Download 98/300: \n",
      "case_00097: 100% 35994/35995 [00:01<00:00, 34909.65KB/s]\n",
      "Download 99/300: \n",
      "case_00098: 100% 113065/113066 [00:02<00:00, 48674.05KB/s]\n",
      "Download 100/300: \n",
      "case_00099: 100% 44531/44532 [00:01<00:00, 40540.26KB/s]\n",
      "Download 101/300: \n",
      "case_00100: 100% 217447/217448 [00:04<00:00, 54185.59KB/s]\n",
      "Download 102/300: \n",
      "case_00101: 100% 222646/222647 [00:04<00:00, 54409.61KB/s]\n",
      "Download 103/300: \n",
      "case_00102: 100% 139727/139728 [00:02<00:00, 46922.13KB/s]\n",
      "Download 104/300: \n",
      "case_00103: 100% 286971/286972 [00:05<00:00, 53241.11KB/s]\n",
      "Download 105/300: \n",
      "case_00104: 100% 58853/58854 [00:01<00:00, 46374.16KB/s]\n",
      "Download 106/300: \n",
      "case_00105: 100% 60940/60941 [00:01<00:00, 44031.97KB/s]\n",
      "Download 107/300: \n",
      "case_00106: 100% 47144/47145 [00:01<00:00, 45702.95KB/s]\n",
      "Download 108/300: \n",
      "case_00107: 100% 34804/34805 [00:00<00:00, 39247.84KB/s]\n",
      "Download 109/300: \n",
      "case_00108: 100% 23687/23688 [00:00<00:00, 35716.72KB/s]\n",
      "Download 110/300: \n",
      "case_00109: 100% 32402/32403 [00:00<00:00, 34243.92KB/s]\n",
      "Download 111/300: \n",
      "case_00110: 100% 16481/16482 [00:00<00:00, 32706.39KB/s]\n",
      "Download 112/300: \n",
      "case_00111: 100% 78705/78706 [00:01<00:00, 45127.93KB/s]\n",
      "Download 113/300: \n",
      "case_00112: 100% 55840/55841 [00:01<00:00, 47240.43KB/s]\n",
      "Download 114/300: \n",
      "case_00113: 100% 22107/22108 [00:00<00:00, 36040.67KB/s]\n",
      "Download 115/300: \n",
      "case_00114: 100% 147217/147218 [00:02<00:00, 53273.40KB/s]\n",
      "Download 116/300: \n",
      "case_00115: 100% 147301/147302 [00:02<00:00, 51700.55KB/s]\n",
      "Download 117/300: \n",
      "case_00116: 100% 196707/196708 [00:03<00:00, 56539.24KB/s]\n",
      "Download 118/300: \n",
      "case_00117: 100% 30684/30685 [00:00<00:00, 37261.69KB/s]\n",
      "Download 119/300: \n",
      "case_00118: 100% 303939/303940 [00:05<00:00, 56876.04KB/s]\n",
      "Download 120/300: \n",
      "case_00119: 100% 44352/44353 [00:01<00:00, 40521.82KB/s]\n",
      "Download 121/300: \n",
      "case_00120: 100% 135413/135414 [00:02<00:00, 51483.02KB/s]\n",
      "Download 122/300: \n",
      "case_00121: 100% 35289/35290 [00:00<00:00, 40608.85KB/s]\n",
      "Download 123/300: \n",
      "case_00122: 100% 25550/25551 [00:00<00:00, 37511.55KB/s]\n",
      "Download 124/300: \n",
      "case_00123: 100% 150859/150860 [00:02<00:00, 50595.10KB/s]\n",
      "Download 125/300: \n",
      "case_00124: 100% 113055/113056 [00:02<00:00, 51790.47KB/s]\n",
      "Download 126/300: \n",
      "case_00125: 100% 64037/64038 [00:01<00:00, 49692.53KB/s]\n",
      "Download 127/300: \n",
      "case_00126: 100% 46555/46556 [00:01<00:00, 40158.25KB/s]\n",
      "Download 128/300: \n",
      "case_00127: 100% 41530/41531 [00:00<00:00, 43435.85KB/s]\n",
      "Download 129/300: \n",
      "case_00128: 100% 87078/87079 [00:01<00:00, 51264.43KB/s]\n",
      "Download 130/300: \n",
      "case_00129: 100% 24054/24055 [00:00<00:00, 34620.49KB/s]\n",
      "Download 131/300: \n",
      "case_00130: 100% 26677/26678 [00:00<00:00, 33156.14KB/s]\n",
      "Download 132/300: \n",
      "case_00131: 100% 66542/66543 [00:01<00:00, 45665.55KB/s]\n",
      "Download 133/300: \n",
      "case_00132: 100% 240243/240244 [00:04<00:00, 55529.27KB/s]\n",
      "Download 134/300: \n",
      "case_00133: 100% 73000/73001 [00:01<00:00, 46490.62KB/s]\n",
      "Download 135/300: \n",
      "case_00134: 100% 24422/24423 [00:00<00:00, 38372.52KB/s]\n",
      "Download 136/300: \n",
      "case_00135: 100% 269658/269659 [00:05<00:00, 52319.60KB/s]\n",
      "Download 137/300: \n",
      "case_00136: 100% 51986/51987 [00:01<00:00, 45816.25KB/s]\n",
      "Download 138/300: \n",
      "case_00137: 100% 47700/47701 [00:01<00:00, 42853.90KB/s]\n",
      "Download 139/300: \n",
      "case_00138: 100% 40601/40602 [00:00<00:00, 42646.68KB/s]\n",
      "Download 140/300: \n",
      "case_00139: 100% 48587/48588 [00:01<00:00, 37221.46KB/s]\n",
      "Download 141/300: \n",
      "case_00140: 100% 129580/129581 [00:02<00:00, 53811.78KB/s]\n",
      "Download 142/300: \n",
      "case_00141: 100% 271847/271848 [00:04<00:00, 55391.46KB/s]\n",
      "Download 143/300: \n",
      "case_00142: 100% 119786/119787 [00:02<00:00, 51969.93KB/s]\n",
      "Download 144/300: \n",
      "case_00143: 100% 39109/39110 [00:00<00:00, 42951.27KB/s]\n",
      "Download 145/300: \n",
      "case_00144: 100% 86697/86698 [00:01<00:00, 43929.21KB/s]\n",
      "Download 146/300: \n",
      "case_00145: 100% 32713/32714 [00:00<00:00, 35405.27KB/s]\n",
      "Download 147/300: \n",
      "case_00146: 100% 281605/281606 [00:05<00:00, 54737.54KB/s]\n",
      "Download 148/300: \n",
      "case_00147: 100% 28532/28533 [00:00<00:00, 39692.35KB/s]\n",
      "Download 149/300: \n",
      "case_00148: 100% 15411/15412 [00:00<00:00, 30613.63KB/s]\n",
      "Download 150/300: \n",
      "case_00149: 100% 47822/47823 [00:01<00:00, 47480.45KB/s]\n",
      "Download 151/300: \n",
      "case_00150: 100% 43249/43250 [00:01<00:00, 39266.82KB/s]\n",
      "Download 152/300: \n",
      "case_00151: 100% 495993/495994 [00:08<00:00, 56731.85KB/s]\n",
      "Download 153/300: \n",
      "case_00152: 100% 19368/19369 [00:00<00:00, 31588.77KB/s]\n",
      "Download 154/300: \n",
      "case_00153: 100% 35727/35728 [00:00<00:00, 40389.32KB/s]\n",
      "Download 155/300: \n",
      "case_00154: 100% 185019/185020 [00:03<00:00, 56182.63KB/s]\n",
      "Download 156/300: \n",
      "case_00155: 100% 235923/235924 [00:11<00:00, 21193.65KB/s]\n",
      "Download 157/300: \n",
      "case_00156: 100% 363352/363353 [00:07<00:00, 47157.33KB/s]\n",
      "Download 158/300: \n",
      "case_00157: 100% 231036/231037 [00:04<00:00, 54801.32KB/s]\n",
      "Download 159/300: \n",
      "case_00158: 100% 345812/345813 [00:06<00:00, 56547.55KB/s]\n",
      "Download 160/300: \n",
      "case_00159: 100% 321877/321878 [00:06<00:00, 47624.20KB/s]\n",
      "Download 161/300: \n",
      "case_00160: 100% 196732/196733 [00:05<00:00, 38039.39KB/s]\n",
      "Download 162/300: \n",
      "case_00161: 100% 25615/25616 [00:00<00:00, 36270.18KB/s]\n",
      "Download 163/300: \n",
      "case_00162: 100% 45384/45385 [00:01<00:00, 41283.94KB/s]\n",
      "Download 164/300: \n",
      "case_00163: 100% 40205/40206 [00:01<00:00, 39564.54KB/s]\n",
      "Download 165/300: \n",
      "case_00164: 100% 44482/44483 [00:00<00:00, 46021.12KB/s]\n",
      "Download 166/300: \n",
      "case_00165: 100% 283401/283402 [00:05<00:00, 54789.80KB/s]\n",
      "Download 167/300: \n",
      "case_00166: 100% 41559/41560 [00:00<00:00, 43001.57KB/s]\n",
      "Download 168/300: \n",
      "case_00167: 100% 41129/41130 [00:01<00:00, 22832.50KB/s]\n",
      "Download 169/300: \n",
      "case_00168: 100% 32048/32049 [00:00<00:00, 39387.14KB/s]\n",
      "Download 170/300: \n",
      "case_00169: 100% 42056/42057 [00:00<00:00, 42141.10KB/s]\n",
      "Download 171/300: \n",
      "case_00170: 100% 130206/130207 [00:02<00:00, 53164.42KB/s]\n",
      "Download 172/300: \n",
      "case_00171: 100% 63813/63814 [00:01<00:00, 47378.55KB/s]\n",
      "Download 173/300: \n",
      "case_00172: 100% 37626/37627 [00:00<00:00, 43025.23KB/s]\n",
      "Download 174/300: \n",
      "case_00173: 100% 45244/45245 [00:01<00:00, 43389.13KB/s]\n",
      "Download 175/300: \n",
      "case_00174: 100% 31894/31895 [00:00<00:00, 39577.11KB/s]\n",
      "Download 176/300: \n",
      "case_00175: 100% 54239/54240 [00:01<00:00, 46928.26KB/s]\n",
      "Download 177/300: \n",
      "case_00176: 100% 41461/41462 [00:00<00:00, 44321.65KB/s]\n",
      "Download 178/300: \n",
      "case_00177: 100% 42626/42627 [00:01<00:00, 42055.60KB/s]\n",
      "Download 179/300: \n",
      "case_00178: 100% 35857/35858 [00:00<00:00, 39933.20KB/s]\n",
      "Download 180/300: \n",
      "case_00179: 100% 49463/49464 [00:01<00:00, 40743.07KB/s]\n",
      "Download 181/300: \n",
      "case_00180: 100% 66993/66994 [00:01<00:00, 45118.71KB/s]\n",
      "Download 182/300: \n",
      "case_00181: 100% 49292/49293 [00:01<00:00, 43502.21KB/s]\n",
      "Download 183/300: \n",
      "case_00182: 100% 38436/38437 [00:00<00:00, 42133.17KB/s]\n",
      "Download 184/300: \n",
      "case_00183: 100% 99950/99951 [00:02<00:00, 48049.05KB/s]\n",
      "Download 185/300: \n",
      "case_00184: 100% 70271/70272 [00:01<00:00, 50329.38KB/s]\n",
      "Download 186/300: \n",
      "case_00185: 100% 99730/99731 [00:02<00:00, 48044.68KB/s]\n",
      "Download 187/300: \n",
      "case_00186: 100% 68574/68575 [00:01<00:00, 46596.22KB/s]\n",
      "Download 188/300: \n",
      "case_00187: 100% 41465/41466 [00:00<00:00, 41797.88KB/s]\n",
      "Download 189/300: \n",
      "case_00188: 100% 173648/173649 [00:03<00:00, 54922.12KB/s]\n",
      "Download 190/300: \n",
      "case_00189: 100% 69794/69795 [00:01<00:00, 44991.18KB/s]\n",
      "Download 191/300: \n",
      "case_00190: 100% 80969/80970 [00:01<00:00, 50027.78KB/s]\n",
      "Download 192/300: \n",
      "case_00191: 100% 146751/146752 [00:02<00:00, 52634.55KB/s]\n",
      "Download 193/300: \n",
      "case_00192: 100% 56112/56113 [00:01<00:00, 43317.82KB/s]\n",
      "Download 194/300: \n",
      "case_00193: 100% 94515/94516 [00:01<00:00, 49768.77KB/s]\n",
      "Download 195/300: \n",
      "case_00194: 100% 56502/56503 [00:01<00:00, 45462.68KB/s]\n",
      "Download 196/300: \n",
      "case_00195: 100% 47638/47639 [00:01<00:00, 46780.21KB/s]\n",
      "Download 197/300: \n",
      "case_00196: 100% 80043/80044 [00:01<00:00, 50740.19KB/s]\n",
      "Download 198/300: \n",
      "case_00197: 100% 71480/71481 [00:01<00:00, 46998.82KB/s]\n",
      "Download 199/300: \n",
      "case_00198: 100% 130795/130796 [00:02<00:00, 49991.59KB/s]\n",
      "Download 200/300: \n",
      "case_00199: 100% 48897/48898 [00:01<00:00, 42132.56KB/s]\n",
      "Download 201/300: \n",
      "case_00200: 100% 51449/51450 [00:01<00:00, 45143.50KB/s]\n",
      "Download 202/300: \n",
      "case_00201: 100% 47090/47091 [00:01<00:00, 44184.50KB/s]\n",
      "Download 203/300: \n",
      "case_00202: 100% 145466/145467 [00:02<00:00, 52219.04KB/s]\n",
      "Download 204/300: \n",
      "case_00203: 100% 295206/295207 [00:06<00:00, 44601.73KB/s]\n",
      "Download 205/300: \n",
      "case_00204: 100% 31576/31577 [00:00<00:00, 40321.50KB/s]\n",
      "Download 206/300: \n",
      "case_00205: 100% 44138/44139 [00:00<00:00, 45710.22KB/s]\n",
      "Download 207/300: \n",
      "case_00206: 100% 22988/22989 [00:00<00:00, 35263.87KB/s]\n",
      "Download 208/300: \n",
      "case_00207: 100% 68719/68720 [00:01<00:00, 49569.62KB/s]\n",
      "Download 209/300: \n",
      "case_00208: 100% 39898/39899 [00:00<00:00, 44963.38KB/s]\n",
      "Download 210/300: \n",
      "case_00209: 100% 50270/50271 [00:01<00:00, 43323.42KB/s]\n",
      "Download 211/300: \n",
      "case_00210: 100% 18415/18416 [00:00<00:00, 31759.95KB/s]\n",
      "Download 212/300: \n",
      "case_00211: 100% 42867/42868 [00:00<00:00, 44275.80KB/s]\n",
      "Download 213/300: \n",
      "case_00212: 100% 42084/42085 [00:00<00:00, 43868.58KB/s]\n",
      "Download 214/300: \n",
      "case_00213: 100% 290128/290129 [00:05<00:00, 54656.44KB/s]\n",
      "Download 215/300: \n",
      "case_00214: 100% 197325/197326 [00:04<00:00, 41733.06KB/s]\n",
      "Download 216/300: \n",
      "case_00215: 100% 32360/32361 [00:00<00:00, 38264.70KB/s]\n",
      "Download 217/300: \n",
      "case_00216: 100% 318160/318161 [00:06<00:00, 47004.36KB/s]\n",
      "Download 218/300: \n",
      "case_00217: 100% 66593/66594 [00:01<00:00, 34760.68KB/s]\n",
      "Download 219/300: \n",
      "case_00218: 100% 73150/73151 [00:01<00:00, 41682.34KB/s]\n",
      "Download 220/300: \n",
      "case_00219: 100% 74788/74789 [00:03<00:00, 19516.41KB/s]\n",
      "Download 221/300: \n",
      "case_00220: 100% 86327/86328 [00:01<00:00, 45376.75KB/s]\n",
      "Download 222/300: \n",
      "case_00221: 100% 68228/68229 [00:01<00:00, 49645.26KB/s]\n",
      "Download 223/300: \n",
      "case_00222: 100% 44420/44421 [00:01<00:00, 40060.80KB/s]\n",
      "Download 224/300: \n",
      "case_00223: 100% 175070/175071 [00:03<00:00, 51579.06KB/s]\n",
      "Download 225/300: \n",
      "case_00224: 100% 41716/41717 [00:01<00:00, 39684.27KB/s]\n",
      "Download 226/300: \n",
      "case_00225: 100% 51437/51438 [00:01<00:00, 35842.86KB/s]\n",
      "Download 227/300: \n",
      "case_00226: 100% 62450/62451 [00:01<00:00, 34691.69KB/s]\n",
      "Download 228/300: \n",
      "case_00227: 100% 66362/66363 [00:01<00:00, 44033.30KB/s]\n",
      "Download 229/300: \n",
      "case_00228: 100% 42517/42518 [00:01<00:00, 40839.09KB/s]\n",
      "Download 230/300: \n",
      "case_00229: 100% 124090/124091 [00:02<00:00, 53542.62KB/s]\n",
      "Download 231/300: \n",
      "case_00230: 100% 46409/46410 [00:01<00:00, 40170.81KB/s]\n",
      "Download 232/300: \n",
      "case_00231: 100% 72366/72367 [00:01<00:00, 50875.00KB/s]\n",
      "Download 233/300: \n",
      "case_00232: 100% 44837/44838 [00:01<00:00, 41789.28KB/s]\n",
      "Download 234/300: \n",
      "case_00233: 100% 41518/41519 [00:00<00:00, 44002.17KB/s]\n",
      "Download 235/300: \n",
      "case_00234: 100% 69470/69471 [00:01<00:00, 46826.84KB/s]\n",
      "Download 236/300: \n",
      "case_00235: 100% 79819/79820 [00:01<00:00, 46708.98KB/s]\n",
      "Download 237/300: \n",
      "case_00236: 100% 28360/28361 [00:00<00:00, 36517.81KB/s]\n",
      "Download 238/300: \n",
      "case_00237: 100% 67799/67800 [00:01<00:00, 48806.27KB/s]\n",
      "Download 239/300: \n",
      "case_00238: 100% 46579/46580 [00:01<00:00, 42090.34KB/s]\n",
      "Download 240/300: \n",
      "case_00239: 100% 42971/42972 [00:01<00:00, 42402.77KB/s]\n",
      "Download 241/300: \n",
      "case_00240: 100% 80533/80534 [00:01<00:00, 44923.35KB/s]\n",
      "Download 242/300: \n",
      "case_00241: 100% 47966/47967 [00:01<00:00, 43928.56KB/s]\n",
      "Download 243/300: \n",
      "case_00242: 100% 39443/39444 [00:00<00:00, 40874.42KB/s]\n",
      "Download 244/300: \n",
      "case_00243: 100% 41461/41462 [00:00<00:00, 42337.05KB/s]\n",
      "Download 245/300: \n",
      "case_00244: 100% 35423/35424 [00:00<00:00, 40814.30KB/s]\n",
      "Download 246/300: \n",
      "case_00245: 100% 59856/59857 [00:01<00:00, 43969.07KB/s]\n",
      "Download 247/300: \n",
      "case_00246: 100% 283908/283909 [00:05<00:00, 54551.96KB/s]\n",
      "Download 248/300: \n",
      "case_00247: 100% 106016/106017 [00:02<00:00, 51630.40KB/s]\n",
      "Download 249/300: \n",
      "case_00248: 100% 26495/26496 [00:00<00:00, 34643.92KB/s]\n",
      "Download 250/300: \n",
      "case_00249: 100% 118824/118825 [00:02<00:00, 44811.92KB/s]\n",
      "Download 251/300: \n",
      "case_00250: 100% 97097/97098 [00:01<00:00, 51414.62KB/s]\n",
      "Download 252/300: \n",
      "case_00251: 100% 22695/22696 [00:00<00:00, 34098.03KB/s]\n",
      "Download 253/300: \n",
      "case_00252: 100% 22888/22889 [00:00<00:00, 32514.40KB/s]\n",
      "Download 254/300: \n",
      "case_00253: 100% 220845/220846 [00:04<00:00, 54038.75KB/s]\n",
      "Download 255/300: \n",
      "case_00254: 100% 121347/121348 [00:02<00:00, 46111.68KB/s]\n",
      "Download 256/300: \n",
      "case_00255: 100% 73537/73538 [00:01<00:00, 44889.72KB/s]\n",
      "Download 257/300: \n",
      "case_00256: 100% 30832/30833 [00:00<00:00, 39565.95KB/s]\n",
      "Download 258/300: \n",
      "case_00257: 100% 15440/15441 [00:00<00:00, 28744.14KB/s]\n",
      "Download 259/300: \n",
      "case_00258: 100% 44551/44552 [00:00<00:00, 44888.09KB/s]\n",
      "Download 260/300: \n",
      "case_00259: 100% 38176/38177 [00:01<00:00, 37990.34KB/s]\n",
      "Download 261/300: \n",
      "case_00260: 100% 25637/25638 [00:00<00:00, 37810.28KB/s]\n",
      "Download 262/300: \n",
      "case_00261: 100% 255984/255985 [00:04<00:00, 55196.82KB/s]\n",
      "Download 263/300: \n",
      "case_00262: 100% 31776/31777 [00:00<00:00, 40891.18KB/s]\n",
      "Download 264/300: \n",
      "case_00263: 100% 310741/310742 [00:05<00:00, 55991.32KB/s]\n",
      "Download 265/300: \n",
      "case_00264: 100% 189605/189606 [00:04<00:00, 47281.00KB/s]\n",
      "Download 266/300: \n",
      "case_00265: 100% 45731/45732 [00:01<00:00, 44674.00KB/s]\n",
      "Download 267/300: \n",
      "case_00266: 100% 42291/42292 [00:01<00:00, 42099.78KB/s]\n",
      "Download 268/300: \n",
      "case_00267: 100% 23594/23595 [00:00<00:00, 28365.11KB/s]\n",
      "Download 269/300: \n",
      "case_00268: 100% 80600/80601 [00:01<00:00, 49114.07KB/s]\n",
      "Download 270/300: \n",
      "case_00269: 100% 45354/45355 [00:01<00:00, 43279.64KB/s]\n",
      "Download 271/300: \n",
      "case_00270: 100% 47591/47592 [00:01<00:00, 44956.73KB/s]\n",
      "Download 272/300: \n",
      "case_00271: 100% 216019/216020 [00:04<00:00, 51188.90KB/s]\n",
      "Download 273/300: \n",
      "case_00272: 100% 271071/271072 [00:06<00:00, 42512.80KB/s]\n",
      "Download 274/300: \n",
      "case_00273: 100% 110309/110310 [00:02<00:00, 39656.27KB/s]\n",
      "Download 275/300: \n",
      "case_00274: 100% 54524/54525 [00:01<00:00, 46086.56KB/s]\n",
      "Download 276/300: \n",
      "case_00275: 100% 38690/38691 [00:00<00:00, 42132.59KB/s]\n",
      "Download 277/300: \n",
      "case_00276: 100% 305614/305615 [00:06<00:00, 45953.20KB/s]\n",
      "Download 278/300: \n",
      "case_00277: 100% 40912/40913 [00:01<00:00, 40877.07KB/s]\n",
      "Download 279/300: \n",
      "case_00278: 100% 82590/82591 [00:01<00:00, 46793.20KB/s]\n",
      "Download 280/300: \n",
      "case_00279: 100% 26124/26125 [00:00<00:00, 36172.94KB/s]\n",
      "Download 281/300: \n",
      "case_00280: 100% 38398/38399 [00:00<00:00, 41822.84KB/s]\n",
      "Download 282/300: \n",
      "case_00281: 100% 123692/123693 [00:02<00:00, 46494.51KB/s]\n",
      "Download 283/300: \n",
      "case_00282: 100% 42431/42432 [00:01<00:00, 42287.90KB/s]\n",
      "Download 284/300: \n",
      "case_00283: 100% 158916/158917 [00:06<00:00, 24584.61KB/s]\n",
      "Download 285/300: \n",
      "case_00284: 100% 113572/113573 [00:02<00:00, 42901.96KB/s]\n",
      "Download 286/300: \n",
      "case_00285: 100% 21479/21480 [00:00<00:00, 34244.39KB/s]\n",
      "Download 287/300: \n",
      "case_00286: 100% 54689/54690 [00:01<00:00, 44514.67KB/s]\n",
      "Download 288/300: \n",
      "case_00287: 100% 26272/26273 [00:00<00:00, 36329.51KB/s]\n",
      "Download 289/300: \n",
      "case_00288: 100% 118662/118663 [00:02<00:00, 52264.67KB/s]\n",
      "Download 290/300: \n",
      "case_00289: 100% 43012/43013 [00:01<00:00, 42109.34KB/s]\n",
      "Download 291/300: \n",
      "case_00290: 100% 276552/276553 [00:05<00:00, 48053.45KB/s]\n",
      "Download 292/300: \n",
      "case_00291: 100% 63322/63323 [00:01<00:00, 45639.97KB/s]\n",
      "Download 293/300: \n",
      "case_00292: 100% 42335/42336 [00:01<00:00, 42216.27KB/s]\n",
      "Download 294/300: \n",
      "case_00293: 100% 264217/264218 [00:04<00:00, 54401.49KB/s]\n",
      "Download 295/300: \n",
      "case_00294: 100% 286098/286099 [00:05<00:00, 55713.83KB/s]\n",
      "Download 296/300: \n",
      "case_00295: 100% 239083/239084 [00:08<00:00, 26710.03KB/s]\n",
      "Download 297/300: \n",
      "case_00296: 100% 40041/40042 [00:01<00:00, 38545.57KB/s]\n",
      "Download 298/300: \n",
      "case_00297: 100% 42888/42889 [00:00<00:00, 44757.55KB/s]\n",
      "Download 299/300: \n",
      "case_00298: 100% 282478/282479 [00:05<00:00, 53958.84KB/s]\n",
      "Download 300/300: \n",
      "case_00299: 100% 280551/280552 [00:05<00:00, 54408.68KB/s]\n"
     ]
    }
   ],
   "source": [
    "%cd kits19\n",
    "!pip3 install -r /content/kits19/requirements.txt\n",
    "! python -m starter_code.get_imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jyxe7G3ecIy9",
    "outputId": "350b8e11-0de2-4e35-ab3d-e0c7fc06f1d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/kits19\n"
     ]
    }
   ],
   "source": [
    "%cd /content/kits19/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "O2OCcivdkrLR",
    "outputId": "b6157633-0739-48cc-c64c-870fa2d5f9aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting medicaltorch\n",
      "  Downloading https://files.pythonhosted.org/packages/5a/85/b3fa267c6cdec058c937a5046e357de61dda938179aeeca72485f13b1fa2/medicaltorch-0.2-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.5.0+cu101)\n",
      "Requirement already satisfied: numpy>=1.14.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.18.5)\n",
      "Requirement already satisfied: nibabel>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (3.0.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (1.4.1)\n",
      "Requirement already satisfied: tqdm>=4.23.0 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (4.41.1)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from medicaltorch) (0.6.0+cu101)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->medicaltorch) (0.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->medicaltorch) (7.0.0)\n",
      "Installing collected packages: medicaltorch\n",
      "Successfully installed medicaltorch-0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install medicaltorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h8vuONiWgN1F"
   },
   "source": [
    "## To visualize our data we need to use this Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rEmgPsHeAPIv"
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(8,8))\n",
    "# from medicaltorch import datasets as mt_datasets\n",
    "# from skimage import color\n",
    "# pair = mt_datasets.SegmentationPair2D(input_filename, gt_filename) \n",
    "# slice_pair = pair.get_pair_slice(175)\n",
    "# input_slice = slice_pair[\"input\"]\n",
    "# gt_slice = slice_pair[\"gt\"]\n",
    "\n",
    "# img = input_slice\n",
    "# label = gt_slice\n",
    "# plt.imshow(label, cmap = 'gray')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DOlhfpUpBIAZ"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# np.unique(label)  #ile wyróżnia nam klas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PUBovd76gS17"
   },
   "source": [
    "## Loading Libraries for performing segmentation using Deep Learning Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "8rrKiP4CURtG",
    "outputId": "823190dc-2af5-408b-e19c-ff2ea007dda2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler, Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from medicaltorch import datasets as mt_datasets\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from medicaltorch import models as mt_models\n",
    "from keras.utils import to_categorical as cat\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WJeN5PG0gZUH"
   },
   "source": [
    "## Reading the data paths for processing and getting cases numbers in file_name variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zc2HAc0GURpj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "train_path = \"/content/kits19/data/\"\n",
    "cases =  next(os.walk(train_path))\n",
    "file_name = cases[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uzIPBhX6gi6z"
   },
   "source": [
    "## Splitting the data into training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gizt_CUg0hmc"
   },
   "outputs": [],
   "source": [
    "train_data = file_name[:240]\n",
    "validation_data = file_name[240:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M_RmEcdPgnMv"
   },
   "source": [
    "## getting the model from pre build library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sQcr4haCAUU3"
   },
   "outputs": [],
   "source": [
    "model = mt_models.Unet(drop_rate=0.2, bn_momentum=0.8)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OP8Gm9aDAUL0"
   },
   "outputs": [],
   "source": [
    "def transform(img, lbl):\n",
    "  \n",
    "  img = img.astype(np.float32)\n",
    "  lbl = lbl.astype(np.float32)\n",
    "  img -= np.mean(img)\n",
    "  img /= 255.0\n",
    "    \n",
    "  return img, lbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bWNhh1g1gsSO"
   },
   "source": [
    "## Declaring classes to make their dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m5bazMsFAUDh"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        # self.transform = transform   \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        global img\n",
    "        global lbl\n",
    "        cases = train_data[idx]\n",
    "        file_path = train_path + cases +'/'\n",
    "        # print(file_path)\n",
    "        content = next(os.walk(file_path))\n",
    "        if 'segmentation.nii.gz' not in content[2]:\n",
    "          pass\n",
    "        else:\n",
    "          input_filename = file_path + content[2][-1]\n",
    "          gt_filename = file_path + content[2][0]\n",
    "          pair = mt_datasets.SegmentationPair2D(input_filename, gt_filename)\n",
    "          slice_pair = pair.get_pair_slice(175)\n",
    "          img = slice_pair[\"input\"]\n",
    "          label = slice_pair[\"gt\"]\n",
    "          img, lbl = transform(img, label)\n",
    "          img = np.resize(img, (224, 224))  \n",
    "          img = torch.from_numpy(img).unsqueeze_(0)\n",
    "          # print('Img shape:', img.shape)\n",
    "          lbl = np.resize(lbl, (224, 224))  \n",
    "          lbl = torch.from_numpy(lbl).unsqueeze_(0)\n",
    "          # print('Img shape:', img.shape)\n",
    "        return img, lbl \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7h9rdtjPX2Fn"
   },
   "outputs": [],
   "source": [
    "\n",
    "class ValidDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        # self.transform = transform\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        global img\n",
    "        global lbl\n",
    "        cases = validation_data[idx]\n",
    "        file_path = train_path + cases +'/'\n",
    "        content = next(os.walk(file_path))\n",
    "        if 'segmentation.nii.gz' not in content[2]:\n",
    "          pass\n",
    "        else:\n",
    "          input_filename = file_path + content[2][-1]\n",
    "          gt_filename = file_path + content[2][0]\n",
    "          pair = mt_datasets.SegmentationPair2D(input_filename, gt_filename)\n",
    "          slice_pair = pair.get_pair_slice(175)\n",
    "          img = slice_pair[\"input\"]\n",
    "          label = slice_pair[\"gt\"]\n",
    "          img, lbl = transform(img, label)\n",
    "          img = np.resize(img, (224, 224))  \n",
    "          img = torch.from_numpy(img).unsqueeze_(0)\n",
    "          \n",
    "          lbl = np.resize(lbl, (224, 224))  \n",
    "          lbl = torch.from_numpy(lbl).unsqueeze_(0)\n",
    "          # print('Img shape:', img.shape)\n",
    "        return img, lbl \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sM4kVU0VgxxZ"
   },
   "source": [
    "## form the dataloaders for further processing of data... Here i have data and label images both..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NYDWwYrIAT38"
   },
   "outputs": [],
   "source": [
    "train_dataset = TrainDataset(train_data) \n",
    "train_loader = DataLoader(train_dataset, batch_size=10, num_workers=0)\n",
    "\n",
    "valid_dataset = ValidDataset(validation_data) \n",
    "valid_loader = DataLoader(valid_dataset, batch_size=10, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R2ScRE5fg6Wn"
   },
   "source": [
    "## Loss function and changing optimizers here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0JftbdIbUPN4"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q4T9Ilehg_UT"
   },
   "source": [
    "## Dice Loss Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0mXTFfWqz13T"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "class DiceCoeff(Function):\n",
    "    \"\"\"Dice coeff for individual examples\"\"\"\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        self.save_for_backward(input, target)\n",
    "        eps = 0.0001\n",
    "        self.inter = torch.dot(input.view(-1), target.view(-1))\n",
    "        self.union = torch.sum(input) + torch.sum(target) + eps\n",
    "\n",
    "        t = (2 * self.inter.float() + eps) / self.union.float()\n",
    "        return t\n",
    "\n",
    "    # This function has only a single output, so it gets only one gradient\n",
    "    def backward(self, grad_output):\n",
    "\n",
    "        input, target = self.saved_variables\n",
    "        grad_input = grad_target = None\n",
    "\n",
    "        if self.needs_input_grad[0]:\n",
    "            grad_input = grad_output * 2 * (target * self.union - self.inter) \\\n",
    "                         / (self.union * self.union)\n",
    "        if self.needs_input_grad[1]:\n",
    "            grad_target = None\n",
    "\n",
    "        return grad_input, grad_target\n",
    "\n",
    "\n",
    "def dice_coeff(input, target):\n",
    "    \"\"\"Dice coeff for batches\"\"\"\n",
    "    if input.is_cuda:\n",
    "        s = torch.FloatTensor(1).cuda().zero_()\n",
    "    else:\n",
    "        s = torch.FloatTensor(1).zero_()\n",
    "\n",
    "    for i, c in enumerate(zip(input, target)):\n",
    "        s = s + DiceCoeff().forward(c[0], c[1])\n",
    "\n",
    "    return s / (i + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EEfNOizPhB4W"
   },
   "source": [
    "# So here our all training starts..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "Rr48NKojWEvL",
    "outputId": "925c5f0a-d124-4528-ff6c-c9eedd11a190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch has started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1569: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number  0 \t\t Training loss value 163.01694520314535 \t\t Validation Loss Value 140.3655128479004 \t\t Dice Loss for train is 0.5288949906826019    Dice loss for validation is 0.34937089184919995\n",
      "Epoch has started\n",
      "epoch number  1 \t\t Training loss value 116.8987242380778 \t\t Validation Loss Value 107.93188858032227 \t\t Dice Loss for train is 0.3025410504390796    Dice loss for validation is 0.31768765300512314\n",
      "Epoch has started\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "model.to(device)\n",
    "history = []\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    train_loss_total = 0.0 \n",
    "    valid_loss_total = 0.0 \n",
    "    tot = 0\n",
    "    tot_train = 0\n",
    "    print('Epoch has started') \n",
    "      \n",
    "    for images, labels in iter(train_loader):\n",
    "      data = images.to(torch.float)\n",
    "      data = images.to(device)\n",
    "      label = labels.to(torch.float)\n",
    "      label = labels.to(device) \n",
    "      # print('step 1 check')\n",
    "      outputs = model(data)\n",
    "      # print('blablabla')\n",
    "      loss = criterion(outputs, label) \n",
    "      optimizer.zero_grad()\n",
    "      loss.backward() \n",
    "      # print('step 2 check')\n",
    "      \n",
    "      optimizer.step() \n",
    "      pred = (outputs > 0.5).float()\n",
    "      tot_train += dice_coeff(pred, label).item()\n",
    "      train_loss_total  += loss.item()\n",
    "\n",
    "    for data, label in iter(valid_loader): \n",
    "      \n",
    "      data = data.to(torch.float)\n",
    "      data = data.to(device)\n",
    "      label = label.to(torch.float)\n",
    "      label = label.to(device) \n",
    "      outputs = model(data)\n",
    "      loss = criterion(outputs, label)\n",
    "      pred = (outputs > 0.5).float()\n",
    "      tot += dice_coeff(pred, label).item()\n",
    "      valid_loss_total  += loss.item()\n",
    " \n",
    "    train_loss_total_avg = train_loss_total / len(train_loader)\n",
    "    valid_loss_total_avg = valid_loss_total / len(valid_loader)\n",
    "    dice_train = tot_train/len(train_loader)\n",
    "    dice_valid = tot/len(valid_loader)\n",
    "\n",
    "    history.append([train_loss_total_avg, valid_loss_total_avg, dice_train, dice_valid]) \n",
    "    print('epoch number ', epoch, \"\t\t\",'Training loss value', train_loss_total_avg , \"\t\t\", 'Validation Loss Value', valid_loss_total_avg  \\\n",
    "          , \"\t\t\", 'Dice Loss for train is', dice_train, \"  \", 'Dice loss for validation is', dice_valid)\n",
    "    \n",
    "history = pd.DataFrame(history, columns=['train_loss', 'valid_loss', 'train_dice_loss', 'valid_dice_loss'])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AQl9jNhPhGgs"
   },
   "source": [
    "## Getting curves for both losses..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1yiOWSPeNPF"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_loss', 'valid_loss']:\n",
    "    plt.plot(history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Negative Log Likelihood')\n",
    "plt.title('Training and Validation Losses')\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for c in ['train_dice_loss', 'valid_dice_loss']:\n",
    "    plt.plot(100 * history[c], label=c)\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Accuracy')\n",
    "plt.title('Training and Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k_SF5fzU2ijA"
   },
   "outputs": [],
   "source": [
    "pyplot.subplot(1, 3, 1) # have two plots in 1 row two columns, first plot\n",
    "# assuming im is batch x channel x h x w and channel is RGB\n",
    "im, mask = next(iter(valid_loader))\n",
    "pred = model(im)\n",
    "pyplot.plot(im[0].detach().cpu().permute(1, 3, 0))\n",
    "pyplot.subplot(1, 3, 2) # second plot\n",
    "pyplot.plot(mask[0].detach().cpu())\n",
    "pyplot.subplot(1, 3, 3) # third plot\n",
    "pyplot.plot(pred[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hsc9V0kU2KLu"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Projekt_UNet_Grupa9_z_errorem/Karo",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
